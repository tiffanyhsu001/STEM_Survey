---
title: "Factor Analysis"
output: html_notebook
---

```{r}
stem = read.csv("pooled_stem.csv")
head(stem)
```

```{r}
library(psych)
library(GPArotation)
library(psychTools)
```

```{r}
# EDA, Correlations
stem_ordinal = stem[24:47]
lowerCor(stem_ordinal)
corPlot(stem_ordinal)

# pick number of factors 
# The blue line shows eigenvalues of actual data and the two red lines (placed on top of each other) show simulated and resampled data. Here we look at the large drops in the actual data and spot the point where it levels off to the right. Also we locate the point of inflection â€“ the point where the gap between simulated data and actual data tends to be minimum.
fa.parallel(stem_ordinal, fa='fa', fm='ml')
```
### Factor Analysis
```{r}
# only consider the loadings more than 0.3 and not loading on more than one factor (called double loading). Note that negative values are acceptable here. 

factor_analysis <- function(n, rotate_method) {
  factor <- fa(stem_ordinal,nfactors = n,rotate = rotate_method, fm="ml")
  cat(n, "Factors")
  print(factor$loadings,cutoff = 0.3)
  
  return(factor)
}  


# factors
threef = factor_analysis(3, "promax")
fourf = factor_analysis(4,"promax")
fivef = factor_analysis(5,"promax")

anova(threef, fourf)
```

```{r}
### making new variables 
# SenseBelonging = 3.15, 3.16 (inverse this), 3.19 - 3.24
# Stress = 3.8, 3.9, 3.10, 3.13 (inverse this),  3.18
# SES = 3.4, 3.5, 3.6

rescale <- function(x_i,n){
    n-x_i
}

# check rescaling
table(stem$Q3.16)
table(sapply(stem$Q3.16,rescale,5))

table(stem$Q3.13)
table(sapply(stem$Q3.13,rescale,4))

# making variables
stem$Belonging_Factor = stem$Q3.15 + sapply(stem$Q3.16,rescale,5) + stem$Q3.19 + stem$Q3.20 + stem$Q3.21 + stem$Q3.22 + stem$Q3.23 + stem$Q3.24

stem$Stress_Factor = stem$Q3.8  + stem$Q3.9 + stem$Q3.10 + sapply(stem$Q3.13,rescale,4) + stem$Q3.18

stem$SES_Factor = stem$Q3.4 + stem$Q3.5 + stem$Q3.6

```

